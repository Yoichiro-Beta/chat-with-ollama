# chat-with-ollama
a plain example on how to connect with a llm running on ollama.
